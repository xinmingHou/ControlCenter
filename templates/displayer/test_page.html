{% load staticfiles %}
<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta http-equiv="X-UA-Compatible" content="ie=edge">
    <title>TEST PAGE</title>

    <link rel="stylesheet" href="{% static 'bootstrap-4.1.3-dist/css/bootstrap.css' %}"  >
    <link rel="stylesheet" href="{% static 'css/base.css' %}" >
    <link rel="stylesheet" href="{% static 'css/fileinput.css' %}" >
</head>
<body>
    <h1>这是网页测试页面</h1>
    <div class="container-fluid">
        
        <div class="row">
            <div class="col-sm-2">
                <div id="navbar-docs">
                    <nav class="navbar navbar-light bg-light position-fixed">
                            <a class="navbar-brand" href="#">Navbar</a>
                            <nav class="nav nav-pills flex-column">
                            <a class="nav-link" href="#item-1">Item 1</a>
                            <nav class="nav nav-pills flex-column">
                                <a class="nav-link ml-3 my-1" href="#item-1-1">Item 1-1</a>
                                <a class="nav-link ml-3 my-1" href="#item-1-2">Item 1-2</a>
                            </nav>
                            <a class="nav-link" href="#item-2">Item 2</a>
                            <a class="nav-link" href="#item-3">Item 3</a>
                            <nav class="nav nav-pills flex-column">
                                <a class="nav-link ml-3 my-1" href="#item-3-1">Item 3-1</a>
                                <a class="nav-link ml-3 my-1" href="#item-3-2">Item 3-2</a>
                            </nav>
                            </nav>
                        </nav>
                </div>
                    
            </div>
            
            <div class="col-sm-10">
                <div data-spy="scroll" data-target="#navbar-docs" data-offset="0">
                        <h4 id="item-1">Item 1</h4>
                        <p>今天，在微软举办的“新一代人工智能开放科研教育平台暨中国高校人工智能科研教育高峰论坛”上，微软亚洲研究院宣布，携手北京大学、中国科学技术大学、西安交通大学和浙江大学四所国内顶尖高校共建新一代人工智能开放科研教育平台，以推动中国人工智能领域科研与教育事业的发展。作为由微软亚洲研究院为该平台提供的三大关键技术之一，Open
                                Platform for AI（OpenPAI）也备受瞩目。
                                事实上，随着人工智能技术的快速发展，各种深度学习框架层出不穷，为了提高效率，更好地让人工智能快速落地，很多企业都很关注深度学习训练的平台化问题。例如，如何提升GPU等硬件资源的利用率？如何节省硬件投入成本？如何支持算法工程师更方便的应用各类深度学习技术，从繁杂的环境运维等工作中解脱出来？等等。
                                为了解决这些问题，微软亚洲研究院和微软（亚洲）互联网工程院基于各自的特长，联合研发、创建了OpenPAI，希望为深度学习提供一个深度定制和优化的人工智能集群管理平台，让人工智能堆栈变得简单、快速、可扩展。
                                为什么要使用OpenPAI? ●为深度学习量身定做，可扩展支撑更多AI和大数据框架
                                通过创新的PAI运行环境支持，几乎所有深度学习框架如CNTK、TensorFlow、PyTorch等无需修改即可运行；其基于Docker的架构则让用户可以方便地扩展更多AI与大数据框架。
                                ●容器与微服务化，让AI流水线实现DevOps OpenPAI 100%基于微服务架构，让AI平台以及开发便于实现DevOps的开发运维模式。 ●支持GPU多租，可统筹集群资源调度与服务管理能力
                                在深度学习负载下，GPU逐渐成为资源调度的一等公民，OpenPAI提供了针对GPU优化的调度算法，丰富的端口管理，支持Virtual Cluster多租机制，可通过Launcher
                                Server为服务作业的运行保驾护航。 ●提供丰富的运营、监控、调试功能，降低运维复杂度 PAI为运营人员提供了硬件、服务、作业的多级监控，同时开发者还可以通过日志、SSH等方便调试作业。
                                ●兼容AI开发工具生态 平台实现了与Visual Studio Tools for AI等开发工具的深度集成，用户可以一站式进行AI开发。 OpenPAI架构与功能简介
                                OpenPAI是由微软亚洲研究院和微软（亚洲）互联网工程院联合研发的，支持多种深度学习、机器学习及大数据任务，可提供大规模GPU集群调度、集群监控、任务监控、分布式存储等功能，且用户界面友好，易于操作。
                                OpenPAI的架构如下图所示，用户通过Web Portal调用REST Server的API提交作业（Job）和监控集群，其它第三方工具也可通过该API进行任务管理。随后REST
                                Server与Launche</p>
                        <h5 id="item-1-1">Item 1-1</h5>
                        <p>今天，在微软举办的“新一代人工智能开放科研教育平台暨中国高校人工智能科研教育高峰论坛”上，微软亚洲研究院宣布，携手北京大学、中国科学技术大学、西安交通大学和浙江大学四所国内顶尖高校共建新一代人工智能开放科研教育平台，以推动中国人工智能领域科研与教育事业的发展。作为由微软亚洲研究院为该平台提供的三大关键技术之一，Open
                                Platform for AI（OpenPAI）也备受瞩目。
                                事实上，随着人工智能技术的快速发展，各种深度学习框架层出不穷，为了提高效率，更好地让人工智能快速落地，很多企业都很关注深度学习训练的平台化问题。例如，如何提升GPU等硬件资源的利用率？如何节省硬件投入成本？如何支持算法工程师更方便的应用各类深度学习技术，从繁杂的环境运维等工作中解脱出来？等等。
                                为了解决这些问题，微软亚洲研究院和微软（亚洲）互联网工程院基于各自的特长，联合研发、创建了OpenPAI，希望为深度学习提供一个深度定制和优化的人工智能集群管理平台，让人工智能堆栈变得简单、快速、可扩展。
                                为什么要使用OpenPAI? ●为深度学习量身定做，可扩展支撑更多AI和大数据框架
                                通过创新的PAI运行环境支持，几乎所有深度学习框架如CNTK、TensorFlow、PyTorch等无需修改即可运行；其基于Docker的架构则让用户可以方便地扩展更多AI与大数据框架。
                                ●容器与微服务化，让AI流水线实现DevOps OpenPAI 100%基于微服务架构，让AI平台以及开发便于实现DevOps的开发运维模式。 ●支持GPU多租，可统筹集群资源调度与服务管理能力
                                在深度学习负载下，GPU逐渐成为资源调度的一等公民，OpenPAI提供了针对GPU优化的调度算法，丰富的端口管理，支持Virtual Cluster多租机制，可通过Launcher
                                Server为服务作业的运行保驾护航。 ●提供丰富的运营、监控、调试功能，降低运维复杂度 PAI为运营人员提供了硬件、服务、作业的多级监控，同时开发者还可以通过日志、SSH等方便调试作业。
                                ●兼容AI开发工具生态 平台实现了与Visual Studio Tools for AI等开发工具的深度集成，用户可以一站式进行AI开发。 OpenPAI架构与功能简介
                                OpenPAI是由微软亚洲研究院和微软（亚洲）互联网工程院联合研发的，支持多种深度学习、机器学习及大数据任务，可提供大规模GPU集群调度、集群监控、任务监控、分布式存储等功能，且用户界面友好，易于操作。
                                OpenPAI的架构如下图所示，用户通过Web Portal调用REST Server的API提交作业（Job）和监控集群，其它第三方工具也可通过该API进行任务管理。随后REST
                                Server与Launche</p>
                        <h5 id="item-1-2">Item 1-2</h5>
                        <p>今天，在微软举办的“新一代人工智能开放科研教育平台暨中国高校人工智能科研教育高峰论坛”上，微软亚洲研究院宣布，携手北京大学、中国科学技术大学、西安交通大学和浙江大学四所国内顶尖高校共建新一代人工智能开放科研教育平台，以推动中国人工智能领域科研与教育事业的发展。作为由微软亚洲研究院为该平台提供的三大关键技术之一，Open
                                Platform for AI（OpenPAI）也备受瞩目。
                                事实上，随着人工智能技术的快速发展，各种深度学习框架层出不穷，为了提高效率，更好地让人工智能快速落地，很多企业都很关注深度学习训练的平台化问题。例如，如何提升GPU等硬件资源的利用率？如何节省硬件投入成本？如何支持算法工程师更方便的应用各类深度学习技术，从繁杂的环境运维等工作中解脱出来？等等。
                                为了解决这些问题，微软亚洲研究院和微软（亚洲）互联网工程院基于各自的特长，联合研发、创建了OpenPAI，希望为深度学习提供一个深度定制和优化的人工智能集群管理平台，让人工智能堆栈变得简单、快速、可扩展。
                                为什么要使用OpenPAI? ●为深度学习量身定做，可扩展支撑更多AI和大数据框架
                                通过创新的PAI运行环境支持，几乎所有深度学习框架如CNTK、TensorFlow、PyTorch等无需修改即可运行；其基于Docker的架构则让用户可以方便地扩展更多AI与大数据框架。
                                ●容器与微服务化，让AI流水线实现DevOps OpenPAI 100%基于微服务架构，让AI平台以及开发便于实现DevOps的开发运维模式。 ●支持GPU多租，可统筹集群资源调度与服务管理能力
                                在深度学习负载下，GPU逐渐成为资源调度的一等公民，OpenPAI提供了针对GPU优化的调度算法，丰富的端口管理，支持Virtual Cluster多租机制，可通过Launcher
                                Server为服务作业的运行保驾护航。 ●提供丰富的运营、监控、调试功能，降低运维复杂度 PAI为运营人员提供了硬件、服务、作业的多级监控，同时开发者还可以通过日志、SSH等方便调试作业。
                                ●兼容AI开发工具生态 平台实现了与Visual Studio Tools for AI等开发工具的深度集成，用户可以一站式进行AI开发。 OpenPAI架构与功能简介
                                OpenPAI是由微软亚洲研究院和微软（亚洲）互联网工程院联合研发的，支持多种深度学习、机器学习及大数据任务，可提供大规模GPU集群调度、集群监控、任务监控、分布式存储等功能，且用户界面友好，易于操作。
                                OpenPAI的架构如下图所示，用户通过Web Portal调用REST Server的API提交作业（Job）和监控集群，其它第三方工具也可通过该API进行任务管理。随后REST
                                Server与Launche</p>
                        <h4 id="item-2">Item 2</h4>
                        <p>今天，在微软举办的“新一代人工智能开放科研教育平台暨中国高校人工智能科研教育高峰论坛”上，微软亚洲研究院宣布，携手北京大学、中国科学技术大学、西安交通大学和浙江大学四所国内顶尖高校共建新一代人工智能开放科研教育平台，以推动中国人工智能领域科研与教育事业的发展。作为由微软亚洲研究院为该平台提供的三大关键技术之一，Open
                                Platform for AI（OpenPAI）也备受瞩目。
                                事实上，随着人工智能技术的快速发展，各种深度学习框架层出不穷，为了提高效率，更好地让人工智能快速落地，很多企业都很关注深度学习训练的平台化问题。例如，如何提升GPU等硬件资源的利用率？如何节省硬件投入成本？如何支持算法工程师更方便的应用各类深度学习技术，从繁杂的环境运维等工作中解脱出来？等等。
                                为了解决这些问题，微软亚洲研究院和微软（亚洲）互联网工程院基于各自的特长，联合研发、创建了OpenPAI，希望为深度学习提供一个深度定制和优化的人工智能集群管理平台，让人工智能堆栈变得简单、快速、可扩展。
                                为什么要使用OpenPAI? ●为深度学习量身定做，可扩展支撑更多AI和大数据框架
                                通过创新的PAI运行环境支持，几乎所有深度学习框架如CNTK、TensorFlow、PyTorch等无需修改即可运行；其基于Docker的架构则让用户可以方便地扩展更多AI与大数据框架。
                                ●容器与微服务化，让AI流水线实现DevOps OpenPAI 100%基于微服务架构，让AI平台以及开发便于实现DevOps的开发运维模式。 ●支持GPU多租，可统筹集群资源调度与服务管理能力
                                在深度学习负载下，GPU逐渐成为资源调度的一等公民，OpenPAI提供了针对GPU优化的调度算法，丰富的端口管理，支持Virtual Cluster多租机制，可通过Launcher
                                Server为服务作业的运行保驾护航。 ●提供丰富的运营、监控、调试功能，降低运维复杂度 PAI为运营人员提供了硬件、服务、作业的多级监控，同时开发者还可以通过日志、SSH等方便调试作业。
                                ●兼容AI开发工具生态 平台实现了与Visual Studio Tools for AI等开发工具的深度集成，用户可以一站式进行AI开发。 OpenPAI架构与功能简介
                                OpenPAI是由微软亚洲研究院和微软（亚洲）互联网工程院联合研发的，支持多种深度学习、机器学习及大数据任务，可提供大规模GPU集群调度、集群监控、任务监控、分布式存储等功能，且用户界面友好，易于操作。
                                OpenPAI的架构如下图所示，用户通过Web Portal调用REST Server的API提交作业（Job）和监控集群，其它第三方工具也可通过该API进行任务管理。随后REST
                                Server与Launche</p>
                        <h4 id="item-3">Item 3</h4>
                        <p>今天，在微软举办的“新一代人工智能开放科研教育平台暨中国高校人工智能科研教育高峰论坛”上，微软亚洲研究院宣布，携手北京大学、中国科学技术大学、西安交通大学和浙江大学四所国内顶尖高校共建新一代人工智能开放科研教育平台，以推动中国人工智能领域科研与教育事业的发展。作为由微软亚洲研究院为该平台提供的三大关键技术之一，Open
                                Platform for AI（OpenPAI）也备受瞩目。
                                事实上，随着人工智能技术的快速发展，各种深度学习框架层出不穷，为了提高效率，更好地让人工智能快速落地，很多企业都很关注深度学习训练的平台化问题。例如，如何提升GPU等硬件资源的利用率？如何节省硬件投入成本？如何支持算法工程师更方便的应用各类深度学习技术，从繁杂的环境运维等工作中解脱出来？等等。
                                为了解决这些问题，微软亚洲研究院和微软（亚洲）互联网工程院基于各自的特长，联合研发、创建了OpenPAI，希望为深度学习提供一个深度定制和优化的人工智能集群管理平台，让人工智能堆栈变得简单、快速、可扩展。
                                为什么要使用OpenPAI? ●为深度学习量身定做，可扩展支撑更多AI和大数据框架
                                通过创新的PAI运行环境支持，几乎所有深度学习框架如CNTK、TensorFlow、PyTorch等无需修改即可运行；其基于Docker的架构则让用户可以方便地扩展更多AI与大数据框架。
                                ●容器与微服务化，让AI流水线实现DevOps OpenPAI 100%基于微服务架构，让AI平台以及开发便于实现DevOps的开发运维模式。 ●支持GPU多租，可统筹集群资源调度与服务管理能力
                                在深度学习负载下，GPU逐渐成为资源调度的一等公民，OpenPAI提供了针对GPU优化的调度算法，丰富的端口管理，支持Virtual Cluster多租机制，可通过Launcher
                                Server为服务作业的运行保驾护航。 ●提供丰富的运营、监控、调试功能，降低运维复杂度 PAI为运营人员提供了硬件、服务、作业的多级监控，同时开发者还可以通过日志、SSH等方便调试作业。
                                ●兼容AI开发工具生态 平台实现了与Visual Studio Tools for AI等开发工具的深度集成，用户可以一站式进行AI开发。 OpenPAI架构与功能简介
                                OpenPAI是由微软亚洲研究院和微软（亚洲）互联网工程院联合研发的，支持多种深度学习、机器学习及大数据任务，可提供大规模GPU集群调度、集群监控、任务监控、分布式存储等功能，且用户界面友好，易于操作。
                                OpenPAI的架构如下图所示，用户通过Web Portal调用REST Server的API提交作业（Job）和监控集群，其它第三方工具也可通过该API进行任务管理。随后REST
                                Server与Launche</p>
                        <h5 id="item-3-1">Item 3-1</h5>
                        <p>今天，在微软举办的“新一代人工智能开放科研教育平台暨中国高校人工智能科研教育高峰论坛”上，微软亚洲研究院宣布，携手北京大学、中国科学技术大学、西安交通大学和浙江大学四所国内顶尖高校共建新一代人工智能开放科研教育平台，以推动中国人工智能领域科研与教育事业的发展。作为由微软亚洲研究院为该平台提供的三大关键技术之一，Open
                                Platform for AI（OpenPAI）也备受瞩目。
                                事实上，随着人工智能技术的快速发展，各种深度学习框架层出不穷，为了提高效率，更好地让人工智能快速落地，很多企业都很关注深度学习训练的平台化问题。例如，如何提升GPU等硬件资源的利用率？如何节省硬件投入成本？如何支持算法工程师更方便的应用各类深度学习技术，从繁杂的环境运维等工作中解脱出来？等等。
                                为了解决这些问题，微软亚洲研究院和微软（亚洲）互联网工程院基于各自的特长，联合研发、创建了OpenPAI，希望为深度学习提供一个深度定制和优化的人工智能集群管理平台，让人工智能堆栈变得简单、快速、可扩展。
                                为什么要使用OpenPAI? ●为深度学习量身定做，可扩展支撑更多AI和大数据框架
                                通过创新的PAI运行环境支持，几乎所有深度学习框架如CNTK、TensorFlow、PyTorch等无需修改即可运行；其基于Docker的架构则让用户可以方便地扩展更多AI与大数据框架。
                                ●容器与微服务化，让AI流水线实现DevOps OpenPAI 100%基于微服务架构，让AI平台以及开发便于实现DevOps的开发运维模式。 ●支持GPU多租，可统筹集群资源调度与服务管理能力
                                在深度学习负载下，GPU逐渐成为资源调度的一等公民，OpenPAI提供了针对GPU优化的调度算法，丰富的端口管理，支持Virtual Cluster多租机制，可通过Launcher
                                Server为服务作业的运行保驾护航。 ●提供丰富的运营、监控、调试功能，降低运维复杂度 PAI为运营人员提供了硬件、服务、作业的多级监控，同时开发者还可以通过日志、SSH等方便调试作业。
                                ●兼容AI开发工具生态 平台实现了与Visual Studio Tools for AI等开发工具的深度集成，用户可以一站式进行AI开发。 OpenPAI架构与功能简介
                                OpenPAI是由微软亚洲研究院和微软（亚洲）互联网工程院联合研发的，支持多种深度学习、机器学习及大数据任务，可提供大规模GPU集群调度、集群监控、任务监控、分布式存储等功能，且用户界面友好，易于操作。
                                OpenPAI的架构如下图所示，用户通过Web Portal调用REST Server的API提交作业（Job）和监控集群，其它第三方工具也可通过该API进行任务管理。随后REST
                                Server与Launche</p>
                        <h5 id="item-3-2">Item 3-2</h5>
                        <p>今天，在微软举办的“新一代人工智能开放科研教育平台暨中国高校人工智能科研教育高峰论坛”上，微软亚洲研究院宣布，携手北京大学、中国科学技术大学、西安交通大学和浙江大学四所国内顶尖高校共建新一代人工智能开放科研教育平台，以推动中国人工智能领域科研与教育事业的发展。作为由微软亚洲研究院为该平台提供的三大关键技术之一，Open
                                Platform for AI（OpenPAI）也备受瞩目。
                                事实上，随着人工智能技术的快速发展，各种深度学习框架层出不穷，为了提高效率，更好地让人工智能快速落地，很多企业都很关注深度学习训练的平台化问题。例如，如何提升GPU等硬件资源的利用率？如何节省硬件投入成本？如何支持算法工程师更方便的应用各类深度学习技术，从繁杂的环境运维等工作中解脱出来？等等。
                                为了解决这些问题，微软亚洲研究院和微软（亚洲）互联网工程院基于各自的特长，联合研发、创建了OpenPAI，希望为深度学习提供一个深度定制和优化的人工智能集群管理平台，让人工智能堆栈变得简单、快速、可扩展。
                                为什么要使用OpenPAI? ●为深度学习量身定做，可扩展支撑更多AI和大数据框架
                                通过创新的PAI运行环境支持，几乎所有深度学习框架如CNTK、TensorFlow、PyTorch等无需修改即可运行；其基于Docker的架构则让用户可以方便地扩展更多AI与大数据框架。
                                ●容器与微服务化，让AI流水线实现DevOps OpenPAI 100%基于微服务架构，让AI平台以及开发便于实现DevOps的开发运维模式。 ●支持GPU多租，可统筹集群资源调度与服务管理能力
                                在深度学习负载下，GPU逐渐成为资源调度的一等公民，OpenPAI提供了针对GPU优化的调度算法，丰富的端口管理，支持Virtual Cluster多租机制，可通过Launcher
                                Server为服务作业的运行保驾护航。 ●提供丰富的运营、监控、调试功能，降低运维复杂度 PAI为运营人员提供了硬件、服务、作业的多级监控，同时开发者还可以通过日志、SSH等方便调试作业。
                                ●兼容AI开发工具生态 平台实现了与Visual Studio Tools for AI等开发工具的深度集成，用户可以一站式进行AI开发。 OpenPAI架构与功能简介
                                OpenPAI是由微软亚洲研究院和微软（亚洲）互联网工程院联合研发的，支持多种深度学习、机器学习及大数据任务，可提供大规模GPU集群调度、集群监控、任务监控、分布式存储等功能，且用户界面友好，易于操作。
                                OpenPAI的架构如下图所示，用户通过Web Portal调用REST Server的API提交作业（Job）和监控集群，其它第三方工具也可通过该API进行任务管理。随后REST
                                Server与Launche</p>
                    </div>

            </div>   
                
        
            </div>

       
            
            

    </div>
    







    <script src="{% static 'js/jquery-3.3.1.js' %}" crossorigin="anonymous"></script>
    <script src="{% static 'js/popper.min.js' %}" crossorigin="anonymous"></script>
    <script src="{% static 'bootstrap-4.1.3-dist/js/bootstrap.js' %}" crossorigin="anonymous"></script>
    <script src="{% static 'js/display.js' %}" crossorigin="anonymous"></script>
    <script src="{% static 'js/fileinput.js' %}" crossorigin="anonymous"></script>
    <script src="{% static 'js/zh.js' %}" crossorigin="anonymous"></script>
    
</body>
</html>